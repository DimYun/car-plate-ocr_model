{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb5a49-4180-42f7-91d5-7d1770d6af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d4c6ad-959c-434d-90e8-1d81f921a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from os import path\n",
    "import sys\n",
    "sys.path.append(path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84857e-6ded-42e7-b782-e4a2b6f8110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "import jpeg4py as jpeg\n",
    "\n",
    "from src.dataset import PlatesCodeDataset\n",
    "from src.lightning_module import OCRModule\n",
    "from src.transforms import get_transforms\n",
    "from src.predict_utils import matrix_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d1715-5859-48f5-a4c6-29a723cd10ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:0'\n",
    "VOCAB = '#&0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZÄÅÖÜĆČĐŠŽАБВГДЕЖЗИКЛМНОПРСТУФХЦЧШЭЮЯ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa70a76-7e4c-4c3d-81d5-70bb20818edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transforms(width=416, height=64, text_size=10, vocab=VOCAB, postprocessing=True, augmentations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776b878-097d-4c2c-bb68-928cee93270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=PlatesCodeDataset(\n",
    "    phase='test',\n",
    "    data_folder='../data/',\n",
    "    reset_flag=False,\n",
    "    # transforms=transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556aa51a-a536-4691-b46d-c8be373b7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = OCRModule.load_from_checkpoint('../experiments/exp1/epoch_epoch=20-valid_string_match=0.965.ckpt')\n",
    "_ = module.to(DEVICE)\n",
    "_ = module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac947dea-08b4-4e53-85b5-de0d14352613",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_texts = []\n",
    "pr_texts = []\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    image, text, _, _ = dataset[i]\n",
    "\n",
    "    transformed_image = transforms(image=image, text='')['image']\n",
    "    predict = module(transformed_image[None].to(DEVICE)).cpu().detach()\n",
    "    string_pred, _ = matrix_to_string(predict, VOCAB)\n",
    "\n",
    "    gt_texts.append(text)\n",
    "    pr_texts.append(string_pred[0])\n",
    "\n",
    "gt_texts = np.array(gt_texts)\n",
    "pr_texts = np.array(pr_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674cfc64-093f-48f7-97d6-f1ccdd3203ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy = {np.mean(gt_texts == pr_texts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1440793c-b416-47bf-953d-d86d57102823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong indexes\n",
    "np.where(gt_texts != pr_texts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83085d8b-5fb3-4d97-9414-19339ebe8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_idx = random.randint(0, len(dataset) - 1)\n",
    "idx = random_idx\n",
    "image, text, _, _ = dataset[idx]\n",
    "transformed_image = transforms(image=image, text='')['image']\n",
    "dummy_input = torch.rand(1, 3, 64, 416, device=DEVICE)\n",
    "print(transformed_image[None].shape, dummy_input.shape)\n",
    "print(f'pred = {pr_texts[idx]}')\n",
    "print(f'true = {gt_texts[idx]}')\n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65370aad-b89f-45c1-919b-2eca3b0de661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e09837411aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to onnx\n",
    "ONNX_MODEL_NAME = '../experiments/exp1/exp-1_plate-ocr-model.onnx'\n",
    "DEVICE = 'cuda'\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "dummy_input = torch.rand(1, 3, 64, 416, device=DEVICE)\n",
    "torch.onnx.export(\n",
    "    module,\n",
    "    dummy_input,\n",
    "    ONNX_MODEL_NAME,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes = {'input': [0], 'output': [0]}, # динамический батч, но можно и статический\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e4d7d3969c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check converted model\n",
    "onnx_model = onnx.load(ONNX_MODEL_NAME)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(onnx.helper.printable_graph(onnx_model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3943fff012f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init session\n",
    "\n",
    "providers = [\n",
    "    # 'CUDAExecutionProvider',\n",
    "    'CPUExecutionProvider',\n",
    "]\n",
    "\n",
    "ort_session = ort.InferenceSession(\n",
    "    ONNX_MODEL_NAME,\n",
    "    providers=providers\n",
    ")\n",
    "\n",
    "print(f'{[input_.name for input_ in ort_session.get_inputs()]}')\n",
    "print(f'{[output_.name for output_ in ort_session.get_outputs()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4ede01182ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input tensor\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "test_1 = '../data/dataset-plates/rus/test/img_140_20170102_080138_277_2215533.jpg'\n",
    "test_2 = '../data/dataset-plates/rus_tl/test/6033578.jpg'\n",
    "image = jpeg.JPEG(test_2).decode()\n",
    "onnx_input = transforms(image=image, text='')['image'][None]\n",
    "onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "print(onnx_input.shape)\n",
    "\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "print(list(ort_inputs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa6d146cc5697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run ONNX Runtime inference\n",
    "ort_outputs = ort_session.run(None, ort_inputs)[0]\n",
    "print(ort_outputs.shape)\n",
    "\n",
    "string_pred, _ = matrix_to_string(torch.from_numpy(ort_outputs), VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ce24b79b5e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(image)\n",
    "string_pred"
   ]
  },
  {
   "cell_type": "code",
   "id": "fe7ae4029171819a",
   "metadata": {},
   "outputs": [],
   "source": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
